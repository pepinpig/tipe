%------------------------------------------
\subsection{Resolution système homogène}
%------------------------------------------------
\note{
  Le système issu de la calibration est homogène, donc la matrice nulle est toujours solution, mais cette solution n’a aucun sens géométrique. Pour éviter cette solution triviale, on cherche une solution non nulle, à un facteur près, qu’on trouve en utilisant la SVD.
}
\begin{frame}{Équations sans \(\lambda\) et système matriciel}
  \input{donnees/big_matrice.tex}
\end{frame}


\begin{frame}{Problème d’optimisation sous contrainte}
\note{
Résolution classique -> solution triviale nulle 
Le système est homogène -> on peut fixé la norme du vecteur $p$ à 1.
On transforme le problème en une minimisation sous contrainte.

En appliquant les multiplicateurs de Lagrange, on obtient une condition d’optimalité : le gradient de la fonction est proportionnel au gradient de la contrainte, ce qui donne une équation aux valeurs propres.
}
Solution triviale \( P = 0 \).  
On impose : \( \|p\|^2 = 1 \)

\vspace{0.8em}
On reformule le problème comme une minimisation sous contrainte :
\[
\min_{\|p\| = 1} \|Ap\|^2
\quad \Leftrightarrow \quad
\min_{\|p\| = 1} p^T A^T A p
\]
\pause
\textbf{Propriété clé :} au minimum, \( p \) vérifie :
\[
\boxed{A^T A p = \lambda p}
\]
  \hyperlink{optimisation-appendix}{
    \beamerbutton{Compléments calcul}
  }

\end{frame}

\begin{frame}{Lien avec les valeurs propres}

\begin{itemize}
  \item \( A^T A \) est symétrique : ses vecteurs propres forment une base.
  \pause
  \item La solution \( p \) est le vecteur propre associé à la plus petite valeur propre.
  \pause
  \item Cela minimise \( \|Ap\| \), donc l’erreur de projection.
\end{itemize}

\vspace{1em}
\[
\boxed{\min \|Ap\| \Rightarrow p = \text{vecteur propre de plus petite valeur propre de } A^T A}
\]

\note{
La matrice \( A^T A \) est symétrique, ce qui garantit qu'elle est diagonalisable et possède une base orthonormée de vecteurs propres.

La solution optimale \( p \) est donc un vecteur propre. Pour minimiser \( \|Ap\| \), il faut prendre celui associé à la plus petite valeur propre.

C’est exactement la direction dans laquelle l’application de \( A \) est la moins « amplifiée ».
}
\end{frame}

\begin{frame}{Résolution par SVD}

\begin{itemize}
  \item On factorise \( A \) : 
  \[
  A = U \Sigma V^T
  \]
  \pause
  \item La solution \( p \) est la dernière colonne de \( V \),
  associée à la plus petite valeur singulière \( \sigma_n \).
\end{itemize}

\vspace{1em}
\[
\boxed{p = v_n \quad \text{tel que} \quad \sigma_n = \min \Sigma}
\]

\note{
La décomposition en valeurs singulières, ou SVD, permet de factoriser n’importe quelle matrice \( A \) en trois matrices : deux orthogonales \( U \) et \( V \), et une diagonale \( \Sigma \) contenant les valeurs singulières.

Ces valeurs sont les racines carrées des valeurs propres de \( A^T A \).

La dernière colonne de \( V \), associée à la plus petite valeur singulière, donne donc directement le vecteur \( p \) recherché.

C’est une méthode très stable numériquement.
}
\end{frame}


%++++++++++++++++++++++++++++++++++++++++++++++++
\subsection{Implémentation}

\begin{frame}{Décomposition SVD : idée générale}
  \begin{minipage}[t][0.8\textheight][t]{0.45\textwidth}
    \vspace*{\fill}
      \hyperlink{SVD-appendix}{
    \beamerbutton{Pseudo code}
  }\\
    \textbf{Étapes principales :}
    \begin{itemize}
      \item<1-> \textbf{1.} Calculer \( A^T A \)
      \item<2-> \textbf{2.} Appliquer QR à \( A^T A \)
      \item<3-> \textbf{3.} Extraire valeurs propres \( \sigma_i^2 \)
      \item<4-> \textbf{4.} Déduire \( V \) puis \( U = \frac{1}{\sigma} A v \)
    \end{itemize}
    \vspace*{\fill}
  \end{minipage}
  \hfill
  \begin{minipage}[t]{0.52\textwidth}
    \vspace*{\fill}
    \only<1>{
      \textbf{1. Produit symétrique :}
      \[
        A^T A \text{ est symétrique, de taille } n \times n
      \]
      \vspace{1em}
      On peut chercher ses valeurs propres via QR.
    }

    \only<2>{
      \textbf{2. Algorithme QR :}
      \[
        A_k = R_k Q_k \Rightarrow A_{k+1} = Q_k^T A_k Q_k
      \]
      \vspace{1em}
      Converge vers matrice diagonale contenant \( \sigma_i^2 \).
    }

    \only<3>{
      \textbf{3. Valeurs singulières :}
      \[
        \sigma_i = \sqrt{\lambda_i}, \quad \text{avec } \lambda_i \text{ valeur propre}
      \]
      \vspace{1em}
      On range les \( \sigma_i \) du plus grand au plus petit.
    }

    \only<4>{
      \textbf{4. Vecteurs singuliers :}
   \[
  v_i \text{ propre de } A^T A \quad \Rightarrow \quad u_i = \textstyle\frac{1}{\sigma_i} A v_i
\]

      \vspace{1em}
      On normalise chaque \( u_i \) pour obtenir \( U \).
    }
    \vspace*{\fill}
  \end{minipage}
\end{frame}
